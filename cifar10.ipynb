{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar el dataset CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(\"Datos de entrenamiento: \", len(x_train))\n",
    "print(\"Datos de validación: \", len(x_test))\n",
    "\n",
    "#Procesamiento de datos\n",
    "print(\"\\nValor original de pixel: \", x_train[0][0][0][0])\n",
    "mean = np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "std = np.std(x_train, axis=(0, 1, 2, 3))\n",
    "x_train = (x_train - mean) / (std + 1e-7)\n",
    "x_test = (x_test - mean) / (std + 1e-7)\n",
    "print(\"Valor procesado de pixel: \", x_train[0][0][0][0])\n",
    "\n",
    "#Aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "#Convertir etiquetas a formato categórico\n",
    "num_classes = 10\n",
    "\n",
    "print(\"\\nEtiqueta original: \", y_train[0][0])\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"Etiqueta categórica: \", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construcción del modelo\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4), input_shape=x_train.shape[1:]),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compilación del modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Configuración de callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "#Entrenar el modelo\n",
    "batch_size = 64\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluación del modelo\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Pérdida: {loss}\")\n",
    "print(f\"Precisión: {accuracy}\")\n",
    "\n",
    "#Guardar el modelo entrenado\n",
    "model.save('cifar10.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Modelo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
